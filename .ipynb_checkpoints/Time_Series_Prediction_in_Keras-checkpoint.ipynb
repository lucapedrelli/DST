{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Author: Luca Pedrelli\n",
    "l.pedrelli@deeplearningitalia.com\n",
    "lucapedrelli@gmail.com\n",
    "\n",
    "Exercitation: Time Series Prediction in Keras\n",
    "\n",
    "NB: This file is realized exclusively for educational purposes\n",
    "\n",
    "'''\n",
    "\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "import pylab\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import Dense, SimpleRNN\n",
    "from keras.models import Input, Model\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.optimizers import SGD, Adam\n",
    " \n",
    "np.random.seed(7)\n",
    "\n",
    "# Mean Squared Error\n",
    "def MSE(X,Y):\n",
    "    return  np.mean((X-Y)**2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "path = '.'\n",
    "\n",
    "data = loadmat(os.path.join(path, 'MG.mat')) # load dataset\n",
    "\n",
    "class Struct(object): pass\n",
    "dataset = Struct()\n",
    "dataset.name = data['dataset'][0][0][0][0]\n",
    "dataset.inputs = data['dataset'][0][0][1][0]\n",
    "dataset.targets = data['dataset'][0][0][2][0]\n",
    "\n",
    "# input dimension\n",
    "Ninputs = dataset.inputs[0].shape[0]  \n",
    "\n",
    "# select the model that achieves the maximum accuracy on validation set\n",
    "optimization_problem = np.argmin   \n",
    "\n",
    "\n",
    "TR_indexes = range(4000) # indexes for training, validation and test set in Piano-midi.de task\n",
    "VL_indexes = range(4000,5000)\n",
    "TS_indexes = range(5000,9999)\n",
    "\n",
    "inputs = dataset.inputs[0][0,:].T\n",
    "targets = dataset.targets[0][0,:].T\n",
    "Noutputs = inputs.shape[0]\n",
    "Full_TR_indexes = list(TR_indexes) + list(VL_indexes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression Task\n",
    "\n",
    "The Mackey-Glass (MG) task is a standard benchmark for chaotic time-series next-step prediction. The input sequence is obtained by a discretization of the following equation:\n",
    "$\\frac{\\partial u(t)}{\\partial t} = \\frac{0.2 u(t-17)}{1 + u(t - 17)} - 0.1 u(t).$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot 1000 time-steps\n",
    "pylab.plot(range(inputs[0:1000].shape[0]),inputs[0:1000]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1)** <br>\n",
    "hyper-parametrization = [Nr, lr]\n",
    "\n",
    "For hyper-parametrization in hiper-parameters: <br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; train model on TR_indexes <br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; evaluate model on VL_indexes (save validation error and hyper-parametrization) <br>\n",
    " \n",
    "**Step 2)** <br>\n",
    "create model (hyper-parametrization with minimum validation error) <br>\n",
    "re-train model on Full-TR_indexes <br>\n",
    "test model on TS_indexes <br>\n",
    "<br>\n",
    "print Train VS Validation VS Test Error\n",
    "\n",
    "Overfitting? Underfitting?\n",
    "\n",
    "Plot Target VS Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Keras RNNs, we need two more dimension\n",
    "inputs = np.expand_dims(inputs, axis=1)\n",
    "targets = np.expand_dims(targets, axis=1)\n",
    "inputs = np.expand_dims(inputs, axis=2)\n",
    "targets = np.expand_dims(targets, axis=2)\n",
    "# input shape: (Nsequences, time-steps, input_dimension)\n",
    "\n",
    "# In this case we have only a sequence, therefore we need stateful = True and\n",
    "#Â a input shape: (time-steps, 1, input_dim).\n",
    "# we join the RNN states between time-steps with stateful=True\n",
    "inputs.shape, targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9999 time-steps, 1-dimensional vector\n",
    "# typically we don't need batch size in input_shape\n",
    "# while with statefull=True we need batch_shape = (batch_size, time_steps, input_dimension) // batche_size and time-steps = 1 for simplicity\n",
    "input_sequence = Input(batch_shape=(1,1,1))\n",
    "hidden = SimpleRNN(10, activation='tanh', use_bias=True, return_sequences=True, stateful=True)(input_sequence)\n",
    "outputs = Dense(1, use_bias=True)(hidden)\n",
    "model = Model(inputs = input_sequence, outputs = outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['mse'])\n",
    "\n",
    "history = model.fit(inputs[Full_TR_indexes,:,:], targets[Full_TR_indexes,:,:],\n",
    "          batch_size=1,\n",
    "          epochs=epochs,\n",
    "          verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.plot(history.history['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs[TS_indexes,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(inputs[TS_indexes,:,:], targets[TS_indexes,:,:], batch_size=1)\n",
    "print('MSE test:', scores[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.predict(inputs[Full_TR_indexes,:,:], batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Learning Curve\n",
    "pylab.plot(outputs[0:500,0,0])\n",
    "pylab.plot(targets[0:500,0,0])\n",
    "pylab.legend(('outputs','targets'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
